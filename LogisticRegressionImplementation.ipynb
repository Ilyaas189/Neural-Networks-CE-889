{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "LogisticRegressionImplementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilyaas189/Neural-Networks-CE-889/blob/main/LogisticRegressionImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNi4244_GOy1"
      },
      "source": [
        "### Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3mM1SM7GOy3"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np                      # F or array manupulation\n",
        "import matplotlib.pyplot as plt         # For plotting the dataset\n",
        "import seaborn as sns                   # For displaying and plotting visual data\n",
        "from sklearn import linear_model        # Linear classification model implementation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JoIDuavGOy6"
      },
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZidw_g0GOy7"
      },
      "source": [
        "import scipy.io as scipy           # For loading matlab dataset \n",
        "data = scipy.loadmat('WLDataAll')  # Loading the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbfvgA7rGOy8"
      },
      "source": [
        "### Extracting the data and labels from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlDFWkOCGOy9"
      },
      "source": [
        "x = data['data']                   # Extracting the features\n",
        "y = data['label']                  # Extracting the labels from the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT-Af--jGOy-"
      },
      "source": [
        "### As the data is not aligned in a regular shape of 360 records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbh9la2DGOzB",
        "outputId": "a7f3c554-f71b-46bb-b660-86cad8f5be82"
      },
      "source": [
        "print(\"Shape of the data is \", x.shape) # Its the shape of the features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the data is  (62, 512, 360)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QSzTW4SGOzG"
      },
      "source": [
        "### Flatten each record by transporting it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cujDAz7mGOzJ"
      },
      "source": [
        "X = []\n",
        "for val in x.T:\n",
        "    X.append(list(val.flatten()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqkgpl-9GOzN",
        "outputId": "66df6da7-719a-4048-83d9-9504e199e415"
      },
      "source": [
        "print(\"Tranformed records\" , np.shape(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tranformed records (360, 31744)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVBqdZOVGOzO"
      },
      "source": [
        "### Reduce the features records using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipgQOF9lGOzP"
      },
      "source": [
        "from sklearn.decomposition import PCA # Reducing the features to limited length\n",
        "pca = PCA()\n",
        "X = pca.fit_transform(np.array(X)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj7S5UOIGOzQ",
        "outputId": "a640bfec-65d0-45b6-fb0b-06fbb053c62b"
      },
      "source": [
        "X.shape # Here is the shrinked dataset shape having the features length of 360"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(360, 360)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk8NgY2kGOzR"
      },
      "source": [
        "y = np.array(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_eapIP3GOzS",
        "outputId": "9e7ac1cb-bca1-4d0a-b2b8-5b9edd0b727a"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVQ92vLFGOzT"
      },
      "source": [
        "### Spliting the data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2LfKW_OGOzT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEDScSuaGOzU"
      },
      "source": [
        "### It seems that it can be differentiated using a Decision Boundary, now definning our class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPwk2nGPGOzV"
      },
      "source": [
        "# implementation of Lgistic Regression from scratch\n",
        "class LogisticRegression: \n",
        "    \n",
        "    # defining parameters such as learning rate, number ot iterations, whether to include intercept, \n",
        "    # and verbose which says whether to print anything or not like, loss etc.\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=50000, fit_intercept=True, verbose=False):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.verbose = verbose\n",
        "    \n",
        "    # function to define the Incercept value.\n",
        "    def __b_intercept(self, X):\n",
        "        # initially we set it as all 1's\n",
        "        intercept = np.ones((X.shape[0], 1))\n",
        "        # then we concatinate them to the value of X, we don't add we just append them at the end.\n",
        "        return np.concatenate((intercept, X), axis=1)\n",
        "\n",
        "    def __sigmoid_function(self, z):\n",
        "        # this is our actual sigmoid function which predicts our yp\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    def __loss(self, yp, y):\n",
        "        # this is the loss function which we use to minimize the error of our model\n",
        "        return (-y * np.log(yp) - (1 - y) * np.log(1 - yp)).mean()\n",
        "    \n",
        "    # this is the function which trains our model.\n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        # as said if we want our intercept term to be added we use fit_intercept=True\n",
        "        if self.fit_intercept:\n",
        "            X = self.__b_intercept(X)\n",
        "        \n",
        "        # weights initialization of our Normal Vector, initially we set it to 0, then we learn it eventually\n",
        "        self.W = np.zeros(X.shape[1])\n",
        "        \n",
        "        # this for loop runs for the number of iterations provided\n",
        "        for i in range(self.num_iterations):\n",
        "            \n",
        "            # this is our W * Xi\n",
        "            z = np.dot(X, self.W)\n",
        "            \n",
        "            # this is where we predict the values of Y based on W and Xi\n",
        "            yp = self.__sigmoid_function(z)\n",
        "            \n",
        "            # this is where the gradient is calculated form the error generated by our model\n",
        "            gradient = np.dot(X.T, (yp - y)) / y.size\n",
        "            \n",
        "            # this is where we update our values of W, so that we can use the new values for the next iteration\n",
        "            self.W -= self.learning_rate * gradient\n",
        "            \n",
        "            # this is our new W * Xi\n",
        "            z = np.dot(X, self.W)\n",
        "            yp = self.__sigmoid_function(z)\n",
        "            \n",
        "            # this is where the loss is calculated\n",
        "            loss = self.__loss(yp, y)\n",
        "            \n",
        "            # as mentioned above if we want to print somehting we use verbose, so if verbose=True then our loss get printed\n",
        "            if(self.verbose ==True and i % 10000 == 0):\n",
        "                print(f'loss: {loss} \\t')\n",
        "    \n",
        "    # this is where we predict the probability values based on out generated W values out of all those iterations.\n",
        "    def predict_prob(self, X):\n",
        "        # as said if we want our intercept term to be added we use fit_intercept=True\n",
        "        if self.fit_intercept:\n",
        "            X = self.__b_intercept(X)\n",
        "        \n",
        "        # this is the final prediction that is generated based on the values learned.\n",
        "        return self.__sigmoid_function(np.dot(X, self.W))\n",
        "    \n",
        "    # this is where we predict the actual values 0 or 1 using round. anything less than 0.5 = 0 or more than 0.5 is 1\n",
        "    def predict(self, X):\n",
        "        return self.predict_prob(X).round()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4tDy2qGOzX"
      },
      "source": [
        "### Creating a class of it, we will give Learning rate as 0.1  and number of iterations as 300000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Fb8f7pGOzZ"
      },
      "source": [
        "model = LogisticRegression(learning_rate=0.1, num_iterations=30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQhDOP4BGOza"
      },
      "source": [
        "### Trainning our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kggF6SEYGOzb",
        "outputId": "cc271bd3-7c75-47f0-c09b-99538ce3e272"
      },
      "source": [
        "%%time\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n",
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in log\n",
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in multiply\n",
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\numpy\\core\\_methods.py:160: RuntimeWarning: invalid value encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wall time: 8.37 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoFkh1ljGOzc"
      },
      "source": [
        "### Checking Prediction of our Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu8t1dqwGOzc",
        "outputId": "e56aea6c-68d3-4f7b-c5fb-482fbc8b3fb7"
      },
      "source": [
        "preds = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYt8elvFGOzc",
        "outputId": "6fd9f836-f9dc-4449-b655-44f91ac5b9f9"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(preds, model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00        96\n",
            "         1.0       1.00      1.00      1.00        23\n",
            "\n",
            "    accuracy                           1.00       119\n",
            "   macro avg       1.00      1.00      1.00       119\n",
            "weighted avg       1.00      1.00      1.00       119\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U068ZFv-GOzd",
        "outputId": "8af416ef-5b3b-45c6-8b2f-77ca9939ea85"
      },
      "source": [
        "cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\user\\anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in exp\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1PH-5oiGOze"
      },
      "source": [
        "# Implementing Logistic Regression from Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52PPq5_cGOze"
      },
      "source": [
        "#### Either you can choose to do all those coding yourself, or what you can do is just import a class form a phenominal library of python called Scikit-Learn, and use it's pre implemented Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCrCqBICGOze"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "model = LogisticRegression(solver='liblinear', random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odg24e9zGOze"
      },
      "source": [
        "#### Usinf the same method of fit to train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Tr6H_aNlGOzf",
        "outputId": "e832ba18-e0eb-43bf-edb9-bbd888156289"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0, solver='liblinear')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsQa2hvGGOzg"
      },
      "source": [
        "#### Trying to predict, and check the value of its prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "aABYumBnGOzh",
        "outputId": "5c499fbf-efc9-4907-8da7-8015b48205d7"
      },
      "source": [
        "model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.90359202e-01, 8.09640798e-01],\n",
              "       [9.97581556e-01, 2.41844420e-03],\n",
              "       [4.64706630e-08, 9.99999954e-01],\n",
              "       [1.00000000e+00, 3.87591655e-14],\n",
              "       [8.23146871e-01, 1.76853129e-01],\n",
              "       [9.96632063e-01, 3.36793707e-03],\n",
              "       [4.49526308e-01, 5.50473692e-01],\n",
              "       [8.25430640e-01, 1.74569360e-01],\n",
              "       [9.50875952e-07, 9.99999049e-01],\n",
              "       [0.00000000e+00, 1.00000000e+00],\n",
              "       [2.06149886e-03, 9.97938501e-01],\n",
              "       [8.04023514e-13, 1.00000000e+00],\n",
              "       [9.77423991e-01, 2.25760093e-02],\n",
              "       [2.18771085e-03, 9.97812289e-01],\n",
              "       [7.59003198e-05, 9.99924100e-01],\n",
              "       [0.00000000e+00, 1.00000000e+00],\n",
              "       [9.99996985e-01, 3.01523278e-06],\n",
              "       [0.00000000e+00, 1.00000000e+00],\n",
              "       [9.99473270e-01, 5.26729918e-04],\n",
              "       [1.00000000e+00, 4.52349926e-16],\n",
              "       [6.10981099e-01, 3.89018901e-01],\n",
              "       [9.97608002e-01, 2.39199831e-03],\n",
              "       [1.42574856e-07, 9.99999857e-01],\n",
              "       [9.47924289e-01, 5.20757114e-02],\n",
              "       [2.15339642e-03, 9.97846604e-01],\n",
              "       [2.91344590e-02, 9.70865541e-01],\n",
              "       [2.78236946e-03, 9.97217631e-01],\n",
              "       [9.99999565e-01, 4.35056217e-07],\n",
              "       [5.35490905e-01, 4.64509095e-01],\n",
              "       [9.99628223e-01, 3.71776697e-04],\n",
              "       [2.65525689e-05, 9.99973447e-01],\n",
              "       [1.35740841e-09, 9.99999999e-01],\n",
              "       [9.99999951e-01, 4.90267634e-08],\n",
              "       [1.46606420e-06, 9.99998534e-01],\n",
              "       [2.83942603e-09, 9.99999997e-01],\n",
              "       [9.99837106e-01, 1.62893612e-04],\n",
              "       [5.45617400e-03, 9.94543826e-01],\n",
              "       [9.99999997e-01, 2.81097848e-09],\n",
              "       [9.99998202e-01, 1.79822750e-06],\n",
              "       [1.53424077e-05, 9.99984658e-01],\n",
              "       [1.40702814e-02, 9.85929719e-01],\n",
              "       [9.99999887e-01, 1.13380817e-07],\n",
              "       [6.53684085e-03, 9.93463159e-01],\n",
              "       [9.99992867e-01, 7.13264673e-06],\n",
              "       [9.99999944e-01, 5.63278338e-08],\n",
              "       [9.99991038e-01, 8.96222724e-06],\n",
              "       [9.27317854e-05, 9.99907268e-01],\n",
              "       [9.99999971e-01, 2.93954026e-08],\n",
              "       [1.93656747e-02, 9.80634325e-01],\n",
              "       [4.11434886e-10, 1.00000000e+00],\n",
              "       [7.55243294e-01, 2.44756706e-01],\n",
              "       [9.99743076e-01, 2.56923644e-04],\n",
              "       [5.83108558e-02, 9.41689144e-01],\n",
              "       [9.67287162e-01, 3.27128376e-02],\n",
              "       [9.99779451e-01, 2.20549146e-04],\n",
              "       [7.78132641e-04, 9.99221867e-01],\n",
              "       [3.66249152e-04, 9.99633751e-01],\n",
              "       [9.98484451e-01, 1.51554929e-03],\n",
              "       [7.61227012e-05, 9.99923877e-01],\n",
              "       [6.62731500e-06, 9.99993373e-01],\n",
              "       [1.57516369e-03, 9.98424836e-01],\n",
              "       [9.99878244e-01, 1.21755881e-04],\n",
              "       [1.53785542e-01, 8.46214458e-01],\n",
              "       [1.52385529e-04, 9.99847614e-01],\n",
              "       [2.29556065e-02, 9.77044394e-01],\n",
              "       [9.99197588e-01, 8.02412130e-04],\n",
              "       [4.44089210e-16, 1.00000000e+00],\n",
              "       [9.99999232e-01, 7.67685536e-07],\n",
              "       [3.22089306e-01, 6.77910694e-01],\n",
              "       [1.25001158e-02, 9.87499884e-01],\n",
              "       [9.40771365e-01, 5.92286346e-02],\n",
              "       [8.01227302e-01, 1.98772698e-01],\n",
              "       [2.15037407e-01, 7.84962593e-01],\n",
              "       [9.99999966e-01, 3.35775439e-08],\n",
              "       [1.07249096e-02, 9.89275090e-01],\n",
              "       [9.98109669e-01, 1.89033054e-03],\n",
              "       [1.69242497e-04, 9.99830758e-01],\n",
              "       [8.99256134e-01, 1.00743866e-01],\n",
              "       [9.99973043e-01, 2.69569229e-05],\n",
              "       [2.30748510e-01, 7.69251490e-01],\n",
              "       [1.41331391e-11, 1.00000000e+00],\n",
              "       [9.99999880e-01, 1.20068715e-07],\n",
              "       [9.98705372e-01, 1.29462838e-03],\n",
              "       [9.99951371e-01, 4.86291955e-05],\n",
              "       [9.61435090e-01, 3.85649105e-02],\n",
              "       [9.99836842e-01, 1.63157866e-04],\n",
              "       [1.00000000e+00, 2.95161714e-22],\n",
              "       [3.84098581e-01, 6.15901419e-01],\n",
              "       [9.99998418e-01, 1.58169086e-06],\n",
              "       [6.65092913e-02, 9.33490709e-01],\n",
              "       [5.78399714e-04, 9.99421600e-01],\n",
              "       [1.00000000e+00, 1.59562622e-10],\n",
              "       [3.86351490e-04, 9.99613649e-01],\n",
              "       [8.61533067e-14, 1.00000000e+00],\n",
              "       [5.82152047e-01, 4.17847953e-01],\n",
              "       [7.34304799e-01, 2.65695201e-01],\n",
              "       [9.73577389e-01, 2.64226115e-02],\n",
              "       [6.17898308e-01, 3.82101692e-01],\n",
              "       [9.99999985e-01, 1.47903714e-08],\n",
              "       [8.83275519e-01, 1.16724481e-01],\n",
              "       [9.98918837e-01, 1.08116253e-03],\n",
              "       [8.96656992e-01, 1.03343008e-01],\n",
              "       [1.04764430e-01, 8.95235570e-01],\n",
              "       [9.99999999e-01, 5.17526121e-10],\n",
              "       [9.99999735e-01, 2.65284939e-07],\n",
              "       [9.89196155e-01, 1.08038447e-02],\n",
              "       [0.00000000e+00, 1.00000000e+00],\n",
              "       [5.51033205e-03, 9.94489668e-01],\n",
              "       [1.72257542e-10, 1.00000000e+00],\n",
              "       [9.53995164e-01, 4.60048357e-02],\n",
              "       [1.00000000e+00, 1.01400917e-10],\n",
              "       [5.02978384e-03, 9.94970216e-01],\n",
              "       [1.79534996e-06, 9.99998205e-01],\n",
              "       [1.16603905e-03, 9.98833961e-01],\n",
              "       [9.92097941e-01, 7.90205885e-03],\n",
              "       [4.65050599e-05, 9.99953495e-01],\n",
              "       [8.59179833e-01, 1.40820167e-01],\n",
              "       [9.99999187e-01, 8.13252976e-07],\n",
              "       [9.99999993e-01, 7.19749636e-09]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDt-d4NyGOzh"
      },
      "source": [
        "### The Confusion matrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdeErUFZGOzh",
        "outputId": "da2573d9-0905-4341-f83c-d1d6386153be"
      },
      "source": [
        "print(classification_report(y, model.predict(X)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.81      0.86      0.83       180\n",
            "           2       0.85      0.79      0.82       180\n",
            "\n",
            "    accuracy                           0.82       360\n",
            "   macro avg       0.83      0.82      0.82       360\n",
            "weighted avg       0.83      0.82      0.82       360\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqzOu2_UGOzi"
      },
      "source": [
        "### Neural Network for Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLQXcKUxGOzi"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=360, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks-g-aISGOzi",
        "outputId": "d2224e1e-bb43-4b47-815f-f1e5c50b2085"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 500)               180500    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 300)               150300    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 50)                15050     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 102       \n",
            "=================================================================\n",
            "Total params: 345,952\n",
            "Trainable params: 345,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgHNjcYaGOzj"
      },
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# y_test = le.fit_transform(y_test)\n",
        "# y_train = le.transform(y_train)\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_test = to_categorical(y_test)\n",
        "y_train = to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "r0efnuSmGOzj",
        "outputId": "1889edd3-6d1f-429e-c03c-13b12b56765d"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 50, validation_data = (X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0511e-05 - accuracy: 1.0000 - val_loss: 21.4627 - val_accuracy: 0.4790\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.9848e-06 - accuracy: 1.0000 - val_loss: 21.4597 - val_accuracy: 0.4790\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.5853e-06 - accuracy: 1.0000 - val_loss: 21.4574 - val_accuracy: 0.4790\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.2035e-06 - accuracy: 1.0000 - val_loss: 21.4551 - val_accuracy: 0.4790\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.8569e-06 - accuracy: 1.0000 - val_loss: 21.4522 - val_accuracy: 0.4790\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.5305e-06 - accuracy: 1.0000 - val_loss: 21.4508 - val_accuracy: 0.4790\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.2180e-06 - accuracy: 1.0000 - val_loss: 21.4485 - val_accuracy: 0.4790\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.9174e-06 - accuracy: 1.0000 - val_loss: 21.4464 - val_accuracy: 0.4790\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.6246e-06 - accuracy: 1.0000 - val_loss: 21.4440 - val_accuracy: 0.4790\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.4169e-06 - accuracy: 1.0000 - val_loss: 21.4418 - val_accuracy: 0.4790\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.1741e-06 - accuracy: 1.0000 - val_loss: 21.4386 - val_accuracy: 0.4790\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.9026e-06 - accuracy: 1.0000 - val_loss: 21.4368 - val_accuracy: 0.4790\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.6538e-06 - accuracy: 1.0000 - val_loss: 21.4344 - val_accuracy: 0.4790\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.4704e-06 - accuracy: 1.0000 - val_loss: 21.4327 - val_accuracy: 0.4790\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.2543e-06 - accuracy: 1.0000 - val_loss: 21.4297 - val_accuracy: 0.4790\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.1049e-06 - accuracy: 1.0000 - val_loss: 21.4279 - val_accuracy: 0.4790\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9100e-06 - accuracy: 1.0000 - val_loss: 21.4259 - val_accuracy: 0.4790\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.7602e-06 - accuracy: 1.0000 - val_loss: 21.4241 - val_accuracy: 0.4790\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.5886e-06 - accuracy: 1.0000 - val_loss: 21.4221 - val_accuracy: 0.4790\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.4605e-06 - accuracy: 1.0000 - val_loss: 21.4203 - val_accuracy: 0.4790\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.3403e-06 - accuracy: 1.0000 - val_loss: 21.4184 - val_accuracy: 0.4790\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.2038e-06 - accuracy: 1.0000 - val_loss: 21.4161 - val_accuracy: 0.4790\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5.0742e-06 - accuracy: 1.0000 - val_loss: 21.4142 - val_accuracy: 0.4790\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.9723e-06 - accuracy: 1.0000 - val_loss: 21.4121 - val_accuracy: 0.4790\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.8403e-06 - accuracy: 1.0000 - val_loss: 21.4104 - val_accuracy: 0.4790\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.7315e-06 - accuracy: 1.0000 - val_loss: 21.4080 - val_accuracy: 0.4790\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.6341e-06 - accuracy: 1.0000 - val_loss: 21.4059 - val_accuracy: 0.4790\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.5445e-06 - accuracy: 1.0000 - val_loss: 21.4039 - val_accuracy: 0.4790\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.4342e-06 - accuracy: 1.0000 - val_loss: 21.4018 - val_accuracy: 0.4790\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4.3388e-06 - accuracy: 1.0000 - val_loss: 21.4003 - val_accuracy: 0.4790\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2626e-06 - accuracy: 1.0000 - val_loss: 21.3987 - val_accuracy: 0.4790\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1691e-06 - accuracy: 1.0000 - val_loss: 21.3970 - val_accuracy: 0.4790\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0935e-06 - accuracy: 1.0000 - val_loss: 21.3949 - val_accuracy: 0.4790\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0109e-06 - accuracy: 1.0000 - val_loss: 21.3931 - val_accuracy: 0.4790\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9308e-06 - accuracy: 1.0000 - val_loss: 21.3913 - val_accuracy: 0.4790\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.8615e-06 - accuracy: 1.0000 - val_loss: 21.3898 - val_accuracy: 0.4790\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7829e-06 - accuracy: 1.0000 - val_loss: 21.3885 - val_accuracy: 0.4790\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.7136e-06 - accuracy: 1.0000 - val_loss: 21.3868 - val_accuracy: 0.4790\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.6602e-06 - accuracy: 1.0000 - val_loss: 21.3852 - val_accuracy: 0.4790\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.5786e-06 - accuracy: 1.0000 - val_loss: 21.3837 - val_accuracy: 0.4790\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.5089e-06 - accuracy: 1.0000 - val_loss: 21.3821 - val_accuracy: 0.4790\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.4436e-06 - accuracy: 1.0000 - val_loss: 21.3804 - val_accuracy: 0.4790\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3897e-06 - accuracy: 1.0000 - val_loss: 21.3791 - val_accuracy: 0.4790\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.3308e-06 - accuracy: 1.0000 - val_loss: 21.3775 - val_accuracy: 0.4790\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2710e-06 - accuracy: 1.0000 - val_loss: 21.3758 - val_accuracy: 0.4790\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.2175e-06 - accuracy: 1.0000 - val_loss: 21.3745 - val_accuracy: 0.4790\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1612e-06 - accuracy: 1.0000 - val_loss: 21.3732 - val_accuracy: 0.4790\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.1255e-06 - accuracy: 1.0000 - val_loss: 21.3716 - val_accuracy: 0.4790\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0647e-06 - accuracy: 1.0000 - val_loss: 21.3697 - val_accuracy: 0.4790\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.0083e-06 - accuracy: 1.0000 - val_loss: 21.3685 - val_accuracy: 0.4790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x222dc51c5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTmH2V98GOzj"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVZ6eutKGOzk"
      },
      "source": [
        "y_actual = []\n",
        "prediction = []\n",
        "\n",
        "for n, i in enumerate(y_pred):\n",
        "    prediction.append(np.argmax(y_pred[n]))\n",
        "    y_actual.append(np.argmax(y_test[n]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3qFKpvpGOzk"
      },
      "source": [
        "### Neural Network Prediction results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9I2U5DdGOzk",
        "outputId": "e6e9f871-df76-4c78-d6f1-783a0584e1c4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(prediction, y_actual))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.45      0.58        94\n",
            "           1       0.22      0.60      0.33        25\n",
            "\n",
            "    accuracy                           0.48       119\n",
            "   macro avg       0.52      0.52      0.45       119\n",
            "weighted avg       0.69      0.48      0.52       119\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PNbHVyPGOzl"
      },
      "source": [
        "### The Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ZboW4HGOzl",
        "outputId": "058f0d5b-8127-4833-faf1-75df357973c1"
      },
      "source": [
        "cm = confusion_matrix(y_actual, prediction)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.imshow(cm)\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}